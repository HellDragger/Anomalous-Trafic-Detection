{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cl502_10\\Desktop\\Anomalous-Trafic-Detection\\anomalous\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from collections import deque\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('./data/NF-UNSW-NB15.csv')  # Replace with your actual dataset path\n",
    "\n",
    "# Feature selection\n",
    "features = ['IN_BYTES', 'OUT_BYTES', 'IN_PKTS', 'OUT_PKTS', 'TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS']\n",
    "target = 'Label'\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Prepare feature and target variables\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Feature Encoding and Normalization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cl502_10\\Desktop\\Anomalous-Trafic-Detection\\anomalous\\Lib\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "c:\\Users\\cl502_10\\Desktop\\Anomalous-Trafic-Detection\\anomalous\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apply UMAP for dimensionality reduction\n",
    "umap_model = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = umap_model.fit_transform(X_scaled)\n",
    "\n",
    "# Visualize the UMAP results\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=y, cmap='viridis', alpha=0.5)\n",
    "plt.colorbar(scatter, label='Label')\n",
    "plt.title('UMAP Visualization of Network Traffic Data')\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.show()\n",
    "\n",
    "print(\"UMAP dimensionality reduction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "STATE_SIZE = 2  # Output of UMAP\n",
    "ACTION_SIZE = 2  # Benign or Malicious\n",
    "REPLAY_MEMORY_SIZE = 2000\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_UPDATE_FREQ = 10\n",
    "\n",
    "# Create Q-network model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=STATE_SIZE, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(ACTION_SIZE, activation='linear'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Experience Replay\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, size):\n",
    "        self.buffer = deque(maxlen=size)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# Initialize model and replay buffer\n",
    "q_network = build_model()\n",
    "target_network = build_model()\n",
    "target_network.set_weights(q_network.get_weights())\n",
    "replay_buffer = ReplayBuffer(REPLAY_MEMORY_SIZE)\n",
    "\n",
    "print(\"DQN model architecture defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(episodes=1000):\n",
    "    for e in range(episodes):\n",
    "        # Initialize state\n",
    "        state = X_umap[np.random.randint(len(X_umap))]\n",
    "        state = np.reshape(state, [1, STATE_SIZE])\n",
    "        total_reward = 0\n",
    "\n",
    "        for time in range(len(X_umap)):\n",
    "            # Select action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = np.random.randint(ACTION_SIZE)\n",
    "            else:\n",
    "                q_values = q_network.predict(state)\n",
    "                action = np.argmax(q_values[0])\n",
    "\n",
    "            # Execute action and observe new state\n",
    "            next_state = X_umap[np.random.randint(len(X_umap))]\n",
    "            reward = 1 if action == y[np.random.randint(len(y))] else -1\n",
    "            total_reward += reward\n",
    "            next_state = np.reshape(next_state, [1, STATE_SIZE])\n",
    "\n",
    "            # Store experience in replay buffer\n",
    "            replay_buffer.add((state, action, reward, next_state))\n",
    "\n",
    "            # Sample a batch of experiences from the replay buffer\n",
    "            if replay_buffer.size() > BATCH_SIZE:\n",
    "                batch = replay_buffer.sample(BATCH_SIZE)\n",
    "                for s, a, r, ns in batch:\n",
    "                    target = r + GAMMA * np.max(target_network.predict(ns)[0])\n",
    "                    target_f = q_network.predict(s)\n",
    "                    target_f[0][a] = target\n",
    "                    q_network.fit(s, target_f, epochs=1, verbose=0)\n",
    "\n",
    "            # Update state\n",
    "            state = next_state\n",
    "\n",
    "            # Update target network periodically\n",
    "            if e % TARGET_UPDATE_FREQ == 0:\n",
    "                target_network.set_weights(q_network.get_weights())\n",
    "\n",
    "        print(f\"Episode: {e}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.01\n",
    "\n",
    "train_dqn()\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict using the trained model\n",
    "def evaluate_model():\n",
    "    predictions = []\n",
    "    for state in X_umap:\n",
    "        state = np.reshape(state, [1, STATE_SIZE])\n",
    "        q_values = q_network.predict(state)\n",
    "        action = np.argmax(q_values[0])\n",
    "        predictions.append(action)\n",
    "\n",
    "    # Convert predictions to numpy array\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    precision = precision_score(y, predictions)\n",
    "    recall = recall_score(y, predictions)\n",
    "    f1 = f1_score(y, predictions)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "evaluate_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
